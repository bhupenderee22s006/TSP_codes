# MNIST  sequential code sing mmd distance metric

def man(a,b):
    return abs(a-b)

import numpy as np
import math
import sys

def kernel(x,y):
    x = np.array(x)
    y = np.array(y)
    #print(np.linalg.norm(x-y))
    return math.exp((-np.linalg.norm(x-y)**2)/(2*1000000))
# def computeMMD(x,y,N):
#     g = [[kernel(x[:,i], x[:,j]) + kernel(y[:,i],y[:,j]) - (2*kernel(x[:,i], y[:,j])) for j in range(N)] for i in range(N)]
#     #print(kernel(x[:,1], y[:,2]))
#     print('MMD function done')
#     return math.sqrt((sum(map(sum,g)) / N**2))

def computeMMD(x, y, N,i,j):
    # Convert x and y to numpy arrays
    x = np.array(x)
    y = np.array(y)
    x = x[:, :N]
    y = y[:, :N]


    # Kxx = np.exp(-np.linalg.norm(x[:, :, None]-x[:, None, :], axis=0)**2/(2*1000000))
    # Kyy = np.exp(-np.linalg.norm(y[:, :, None]-y[:, None, :], axis=0)**2/(2*1000000))
    # Kxy = np.exp(-np.linalg.norm(x[:, :, None]-y[:, None, :], axis=0)**2/(2*1000000))

    
    # Compute kernel matrices using broadcasting
    # Kxx = kernel(x[:, None], x[None, :])  # Kernel matrix for x with itself
    # Kyy = kernel(y[:, None], y[None, :])  # Kernel matrix for y with itself
    # Kxy = kernel(x[:, None], y[None, :])  # Kernel matrix for x with y
    #print('MMD function done')

    # Calculate the MMD using vectorized operations
    # MMD_squared = (np.sum(Kxx) + np.sum(Kyy) - 2 * np.sum(Kxy)) / (N**2)
    MMD_squared = (np.sum(np.exp(-np.linalg.norm(x[:, :, None]-x[:, None, :], axis=0)**2/(2*1000000))) + 
                    np.sum(np.exp(-np.linalg.norm(y[:, :, None]-y[:, None, :], axis=0)**2/(2*1000000))) - 
                    2 * np.sum(np.exp(-np.linalg.norm(x[:, :, None]-y[:, None, :], axis=0)**2/(2*1000000)))) / (N**2)
    #print(f'MMD_squared = {MMD_squared}')
    MMD_squared_abs = abs(MMD_squared)
    # print(np.linalg.norm(x[:, :, None]-x[:, None, :], axis=0)**2, np.linalg.norm(y[:, :, None]-y[:, None, :], axis=0)**2, np.linalg.norm(x[:, :, None]-y[:, None, :], axis=0)**2)
    # print(i,j,MMD_squared)
    return np.sqrt(MMD_squared_abs)
def update_optimized(x, y, n):
    # Convert x and y to numpy arrays if they aren't already
    x = np.asarray(x)
    y = np.asarray(y)

    # Extract the last elements
    xn1 = x[n-1]
    yn1 = y[n-1]

    # Compute all kernel values at once
    kernel_x = kernel(x[:n], xn1)
    kernel_y = kernel(y[:n], yn1)
    kernel_xy = kernel(x[:n], yn1)

    # Compute the sum for the first part
    sum1 = np.sum(kernel_x + kernel_y - 2 * kernel_xy)

    # Compute the sum for the second part (excluding the last element)
    kernel_x_m = kernel(x[:n-1], xn1)
    kernel_y_m = kernel(y[:n-1], yn1)
    kernel_xy_m = kernel(x[:n-1], yn1)
    sum2 = np.sum(kernel_x_m + kernel_y_m - 2 * kernel_xy_m)

    # Return the final result
    return (sum1 + sum2) / (n**2)

#lst = [[0,10,6,5,9],[10,0,8,7,2],[6,8,0,1,4],[5,7,1,0,3],[9,2,4,3,0]]
import random
S = 50      # total number of sequences
M = 5      # number of sequences per cluster
K = 10      # number of clusters
# means = [i for i in range(K) for j in range(M)]

correct = [[(M*i)+j for j in range(M)]for i in range(K)]
# Nvec = [20, 40, 60, 80, 100, 120, 140]  # Number of elements in each stream
print(correct)
import numpy as np
import pickle
with open('MNIST_50_arms_10_clusters_norm1.pkl', 'rb') as pkl_file:
    y_all = pickle.load(pkl_file)

def wrong_streams_ratio(C_sort, correct, S=50):
    K = len(correct)
    # S = 50 # hard coded
    num_wrong_streams = 0
    for k in range(K):
        wrong_streams_k = np.setdiff1d(np.array(C_sort[k]), np.array(correct[k]))
        num_wrong_streams = num_wrong_streams + len(wrong_streams_k)
    return num_wrong_streams/S

col_indices = np.random.choice(1000, 200, replace=False)
print(col_indices)

import math
#constvec = [1.3,1.4,1.5,1.6,1.7,1.8,1.9,2]
constvec = [170,180,190,200,210,220,230,240]
Pe = np.zeros(len(constvec))
lnPe=np.zeros(len(constvec))
expsamples=np.zeros(len(constvec))
print(Pe,lnPe,expsamples)

for ii in range(len(constvec)):
    const = constvec[ii]
    iter_sum = 0
    error = 0
    total = 0
    while error < 1:
        ##############  INITIALISATION  ################
        # cluster indices 0 to M-1 and an empty list lst

        col_indices = np.random.choice(1000, nn, replace=False)
        y = {}
        for s in range(S):
            y[s] = y_all[s][:, col_indices]

        clusters = [[i] for i in range(M)]
        lst = [[] for i in range(M)]

        # generate first 2 samples to initialize MMD estimate
        nn = 2
        # X = np.asarray([np.random.normal(means[j],1,nn) for j in range(M)])

        ####    Calculating initial MMDs between each pair of sequences    ####

        lst_dseq =np.zeros((S,S))
        for i in range(1,S):
            for j in range(i):
                lst_dseq[i][j] = computeMMD(y[i],y[j],nn)
                lst_dseq[j][i] = lst_dseq[i][j]
        #print(lst_fixed)

        ##### TEST-STATISTIC Tn INITIALISATION #####
        Tn = 0
        #print(np.min(lst_index,axis = 0))               #it will a column matrix of all 0
        #print(np.min(lst_index,axis = 1))                #it will a row matrix of all 0

        #minval = np.min(lst_fixed[np.nonzero(lst_fixed)])         #will give you the non zero min value of the matrix
        #print(minval)

        #[min_i,min_j] = np.where(lst_fixed==minval)       #will give the index of the  min value of the matrix
        #print([min_i,min_j])

        #Tn = minval    #minimum inter-cluster distance
        #print('Minimum inter-cluster distance after iteration ', nn, ':', Tn)

        while Tn < (const/(nn)):
            nn =nn + 1

            lst_dc = [[] for i in range(M)]
            lst_dc = [[lst_dseq[i][j] for j in range(i+1)] for i in range(M)]
            for i in range(M):
                for j in range(M):
                    if i<j:
                        lst_dc[i].append(lst_dc[j][i])
            #print(lst_new)
            #####
            # Code for SLINK
            clusters = [[i] for i in range(M)]
            # Merge closest clusters till number of clusters is equal to K
            while len(clusters)>K:

                ####    FIND MINIMUM    ####

                #mi = sys.float_info.max
                mi = 100
                for i in range(len(lst_dc)):
                    for j in range(i+1):
                        if i != j:
                            if lst_dc[i][j] < mi:
                                mi = lst_dc[i][j]
                                a,b = [i,j]
                #print("the values of a and b are :", a,b)
                clusters[b].extend(clusters[a])  #add the elements of a to b at the end
                del clusters[a]                   #delete cluster a
                #print(clusters)

                ####    MERGE ROWS  ####
                #print("the lst[b] is ",lst[b])
                #print("the lst[a] is ",lst[a])
                for i in range(len(lst_dc[b])):        #merge rows 'a' and 'b'
                    if min(lst_dc[a][i],lst_dc[b][i]) != 0:
                        lst_dc[b][i] = min(lst_dc[a][i],lst_dc[b][i])
                del lst_dc[a]

                ####    UPDATE ROWS     ####
                for i in range(len(lst_dc)):       #update all other rows
                    if i!=b:
                        lst_dc[i][b] = min(lst_dc[i][a],lst_dc[i][b])
                    del lst_dc[i][a]   #new statement

                #print('dist matrix', lst)
                #print('dist matrix 2', dist)
                #print('clusters',clusters)

            #print('Clusters after iteration ', nn, ':', clusters)

            mi = 100
            for i in range(len(lst_dc)):
                for j in range(i+1):
                    if i != j:
                        if lst_dc[i][j] < mi:
                            mi = lst_dc[i][j]
            Tn = mi

            # generate one more sample for each data stream
            # z = np.asarray([np.random.normal(means[j],1,1) for j in range(M) ])  #creates a 1 dim array with means and SD 1
            # X = np.append(X,z,axis=1)       # new samples   #axis =1 means it will add the values of z along column wise

            #Update MMDs between each pair of data streams
            lst_dseq_1=np.zeros((M,M))
            for i in range(M):
                for j in range(i):
                    lst_dseq_1[i,j] = math.sqrt(((lst_dseq[i][j]*(nn-1)/nn)**2) + update(y[i,:],y[j,:],nn))      # updated distances
                    lst_dseq_1[j,i]=lst_dseq_1[i,j]
            for i in range(M):
                for j in range(M):
                    lst_dseq[i,j] =lst_dseq_1[i,j]

        #print('Minimum inter-cluster distance after iteration ', nn, ':', Tn)
        #print('Clusters after iteration ', nn, ':', clusters)
        #print('Errors', error)
        #print('Total', total)

        # Check if clustering is correct and update errors and number of samples taken
        iter_sum += nn
        # CHECKING IF IT'S CORRECT
        clusters.sort()
        C_sort = []
        for x in clusters:
            x.sort()
            C_sort.append(x)

        if C_sort != correct:
            error = error + 1
        total = total + 1

        #print(C_sort)


    Pe[ii] = error/total
    lnPe[ii] = math.log(Pe[ii])
    expsamples[ii]= iter_sum/total
    print(lnPe[ii],expsamples[ii])

print(total,expsamples,lnPe)
print(iter_sum / total)



